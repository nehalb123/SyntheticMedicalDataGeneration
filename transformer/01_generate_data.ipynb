{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start using the `tensor2tensor` models, we first have to get our data into a format that `tensor2tensor` can digest. This means defining a custom `Problem` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run this only once - Sets up TF Eager execution.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Enable Eager execution - useful for seeing the generated data.\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0904 18:18:29.019985 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0904 18:18:31.300210 140425123104576 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0904 18:18:32.220480 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/utils/metrics_hook.py:28: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "W0904 18:18:32.226704 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0904 18:18:32.228066 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0904 18:18:32.244130 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:109: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
      "\n",
      "W0904 18:18:32.245685 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:780: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Setting a random seed.\n",
    "\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "\n",
    "# Set a seed so that we have deterministic outputs.\n",
    "RANDOM_SEED = 301\n",
    "trainer_lib.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run for setting up directories.\n",
    "\n",
    "import os\n",
    "\n",
    "# Setup and create directories.\n",
    "DATA_DIR = os.path.expanduser(\"../data/t2t_experiments/transformer/low_resource/full_context/data\")\n",
    "OUTPUT_DIR = os.path.expanduser(\"../data/t2t_experiments/transformer/low_resource/full_context/output\")\n",
    "TMP_DIR = os.path.expanduser(\"/mnt/\")\n",
    "\n",
    "# Create them.\n",
    "tf.gfile.MakeDirs(DATA_DIR)\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "tf.gfile.MakeDirs(TMP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.utils import registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@registry.register_problem\n",
    "\n",
    "class MimicDischargeSummaries(text_problems.Text2TextProblem):\n",
    "    \n",
    "    @property\n",
    "    def is_generate_per_split(self):\n",
    "        # our data already has pre-existing splits so we return true\n",
    "        return True\n",
    "\n",
    "    def generate_samples(self, data_dir, tmp_dir, dataset_split):\n",
    "        \n",
    "        del tmp_dir\n",
    "        \n",
    "        _train = (dataset_split == problem.DatasetSplit.TRAIN)\n",
    "        _eval = (dataset_split == problem.DatasetSplit.EVAL)\n",
    "        \n",
    "        dataset = \"train\" if _train else \"val\" if _eval else \"test\"\n",
    "        \n",
    "        full_context = \"full_context\" in str(data_dir) # returns a boolean\n",
    "        directory = \"../data/preprocessed/low_resource/\"\n",
    "        tgt = directory + \"tgt-\" + dataset + \".txt\"\n",
    "\n",
    "        if full_context == True:\n",
    "            src = directory + \"src-\" + dataset + \".txt\"\n",
    "        else:\n",
    "            directory += \"other_contexts/\" \n",
    "            context = str(data_dir)[39:-5] # this index needs to be changed if file paths are changed\n",
    "            src = directory + \"src-\" + dataset + \"-\" + context + \".txt\"\n",
    "        \n",
    "        f_src = open(src,'r')\n",
    "        f_tgt = open(tgt,'r')\n",
    "        \n",
    "        context_data = f_src.readline()\n",
    "        discharge_summary = f_tgt.readline()\n",
    "\n",
    "        while context_data:\n",
    "            yield {\n",
    "              \"inputs\"  : context_data,\n",
    "              \"targets\" : discharge_summary,\n",
    "            }\n",
    "            \n",
    "            context_data = f_src.readline()\n",
    "            discharge_summary = f_tgt.readline()\n",
    "            \n",
    "        f_src.close()\n",
    "        f_tgt.close()\n",
    "\n",
    "    @property\n",
    "    def vocab_type(self):\n",
    "        # SUBWORD and CHARACTER are fully invertible -- but SUBWORD provides a good\n",
    "        # tradeoff between CHARACTER and TOKEN.\n",
    "        return text_problems.VocabType.SUBWORD\n",
    "\n",
    "    @property\n",
    "    def approx_vocab_size(self):\n",
    "        # Approximate vocab size to generate. Only for VocabType.SUBWORD.\n",
    "        return 2**15  # ~32k - this is the default setting\n",
    "\n",
    "    @property\n",
    "    def dataset_splits(self):\n",
    "        return [{\n",
    "            \"split\": problem.DatasetSplit.TRAIN,\n",
    "            \"shards\": 80\n",
    "        }, {\n",
    "            \"split\": problem.DatasetSplit.EVAL,\n",
    "            \"shards\": 10\n",
    "        }, {\n",
    "            \"split\": problem.DatasetSplit.TEST,\n",
    "            \"shards\": 10\n",
    "        }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we instantiate the problem and run it for the full context data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 18:19:54.778185 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:343: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "W0904 18:19:54.779488 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:349: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0904 18:20:43.752292 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:355: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0904 18:20:43.754397 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/text_encoder.py:944: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0904 18:20:43.809778 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:164: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W0904 18:21:04.638908 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:183: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n",
      "W0904 18:21:43.317981 140425123104576 deprecation.py:323] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:469: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "W0904 18:21:43.325965 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:513: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mimic_problem = MimicDischargeSummaries()\n",
    "mimic_problem.generate_data(DATA_DIR, TMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run it in a loop instead for each individual context type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0802 19:05:31.212889 139639908783936 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:343: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "W0802 19:05:31.213634 139639908783936 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:349: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0802 19:08:39.032947 139639908783936 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:355: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0802 19:08:39.034780 139639908783936 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/text_encoder.py:944: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0802 19:08:39.085365 139639908783936 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:164: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W0802 19:11:46.960594 139639908783936 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:183: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n",
      "W0802 19:12:35.876786 139639908783936 deprecation.py:323] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:469: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "W0802 19:12:35.887185 139639908783936 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/generator_utils.py:513: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_list = ['h','h-gae','h-gae-d','h-gae-p','h-gae-d-p','h-gae-d-p-m','h-gae-d-p-m-t','h-gae-d-p-m-l']\n",
    "\n",
    "for context in context_list:\n",
    "    # Setup and create directories.\n",
    "    DATA_DIR = os.path.expanduser(\"../data/t2t_experiments/other_contexts/\"+context+\"/data\")\n",
    "    OUTPUT_DIR = os.path.expanduser(\"../data/t2t_experiments/other_contexts/\"+context+\"/output\")\n",
    "    TMP_DIR = os.path.expanduser(\"/mnt/\")\n",
    "\n",
    "    # Create them.\n",
    "    tf.gfile.MakeDirs(DATA_DIR)\n",
    "    tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "    tf.gfile.MakeDirs(TMP_DIR)\n",
    "    \n",
    "    mimic_problem.generate_data(DATA_DIR, TMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 18:22:27.944880 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/text_problems.py:394: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "W0904 18:22:27.945790 140425123104576 deprecation_wrapper.py:119] From /home/aa5118/anaconda3/envs/tf/lib/python3.7/site-packages/tensor2tensor/data_generators/problem.py:705: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Input: tf.Tensor(\n",
      "[   79    71    52  1899     6    43     6    33    19    57    71   429\n",
      "   367     3   770     4   364     3  1149     4   365     3   325     4\n",
      "   366     3   339    60  2054    94     7   949   139  2915    24   176\n",
      "   136   891  1307     7   582   146   149    60    94     7   136   298\n",
      "   149     7    94   822   245     7   705   303   741     7   102   591\n",
      "   124    15   325    54   820     7  2749   268   741    60   630   444\n",
      "   761   176    55   828   891    94     4   362   277   368     3  1156\n",
      "  1345  1564     5    21     9  7064  2925     7  1156  1345  3868     5\n",
      "   105     9 11939 12298 11326     7   674     5  1825   968     7  1433\n",
      "  4825  6989     5 22037 11326     4   235     3   812    11    92     4\n",
      "   343     3   227   232     5 11345     5   111     6    81     5    30\n",
      "     7   191     5  1098     5    18     6    37     5    30     7   225\n",
      "     5   170     5    48     6    38     5    30     7   230   229     5\n",
      "   113     5    48     6    38     7   215     5   113     9    26     5\n",
      "   223     7   480     5   171     9    35     5   223     7   252     5\n",
      "    67     9    45   106   238   104   107     5    33     9   216     5\n",
      "   112     6    81     7   273    60   177     5    40     9    45     5\n",
      "    18     6    37     7   212     5   941     5    48     6    38     7\n",
      "   209     5    16     9    26     5    18     6    37     5    30     7\n",
      "   269     5    21     9    16     5    18     6    37     7   250     5\n",
      "   431     5   248     7   300     5    26     9    16     5    18     6\n",
      "    37     7   187     5    33     9    32     5    48     6    38     7\n",
      "   204     5  1851     5    48     6    38     7   213   214     5   135\n",
      "     5    18     6    37     7   202     5  1051     9    32   106   234\n",
      "     5   113     9    42     5   138     6    37     7   447   414   215\n",
      "   162    16     9    21     5    92     7   251     5   246     9    26\n",
      "     5   239     5    30     7   247     5   246     9    40   106   243\n",
      "   104   107     5    50     9    26     5   111     6    81     4    38\n",
      "   369     1], shape=(338,), dtype=int64)\n",
      "Tensor Target: tf.Tensor([ 79  71  52 ...   2 599   1], shape=(3113,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tfe = tf.contrib.eager\n",
    "\n",
    "Modes = tf.estimator.ModeKeys\n",
    "\n",
    "# We can iterate over our examples by making an iterator and calling next on it.\n",
    "eager_iterator = tfe.Iterator(mimic_problem.dataset(Modes.EVAL, DATA_DIR))\n",
    "example = eager_iterator.next()\n",
    "\n",
    "input_tensor = example[\"inputs\"]\n",
    "target_tensor = example[\"targets\"]\n",
    "\n",
    "# The tensors are actually encoded using the generated vocabulary file -- you\n",
    "# can inspect the actual vocab file in DATA_DIR.\n",
    "print(\"Tensor Input: \" + str(input_tensor))\n",
    "print(\"Tensor Target: \" + str(target_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cell is not executed in order to protect patient privacy. Executing it will show the decoded context data and discharge summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the encoders to decode the tensors to the actual input text.\n",
    "input_encoder = mimic_problem.get_feature_encoders(\n",
    "    data_dir=DATA_DIR)[\"inputs\"]\n",
    "target_encoder = mimic_problem.get_feature_encoders(\n",
    "    data_dir=DATA_DIR)[\"targets\"]\n",
    "\n",
    "input_decoded = input_encoder.decode(input_tensor.numpy())\n",
    "target_decoded = target_encoder.decode(target_tensor.numpy())\n",
    "\n",
    "print(\"Decoded Input: \" + input_decoded)\n",
    "print(\"Decoded Target: \" + target_decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
