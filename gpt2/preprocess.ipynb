{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_resource=True # change as appropriate\n",
    "\n",
    "if low_resource == True:\n",
    "    DATA = Path('../data/preprocessed/low_resource/')\n",
    "    GPT2 = Path('../data/gpt2/low_resource')\n",
    "else:\n",
    "    DATA = Path('../data/preprocessed/')\n",
    "    GPT2 = Path('../data/gpt2')\n",
    "    \n",
    "GPT2.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA/'src-train.txt', 'r') as f:\n",
    "    train_src = f.readlines()\n",
    "train_src=pd.DataFrame({'text':train_src})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA/'tgt-train.txt', 'r') as f:\n",
    "    train_tgt = f.readlines()\n",
    "train_tgt=pd.DataFrame({'text':train_tgt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in train_src.iterrows():\n",
    "    src = row['text'][:-1]\n",
    "    src = src.split()[:512]\n",
    "    src_len = len(src)\n",
    "    tgt_len = 1024 - src_len #gpt2 can only process inputs of max 1024 tokens in length\n",
    "    tgt = train_tgt['text'][i]\n",
    "    tgt = tgt.split()[:tgt_len]\n",
    "    combined = \"<|startoftext|>\" + \" \".join(src) + \" = \" + \" \".join(tgt) + \"<|endoftext|>\"\n",
    "    row['text'] = combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src['text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(GPT2/'input-text.txt', train_src, fmt='%s', newline=os.linesep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA/'src-val.txt', 'r') as f:\n",
    "    val_src = f.readlines()\n",
    "val_src=pd.DataFrame({'text':val_src})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA/'tgt-val.txt', 'r') as f:\n",
    "    val_tgt = f.readlines()\n",
    "val_tgt=pd.DataFrame({'text':val_tgt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in val_src.iterrows():\n",
    "    src = row['text'][:-1]\n",
    "    src = src.split()[:512]\n",
    "    src_len = len(src)\n",
    "    tgt_len = 1024 - src_len #gpt2 can only process inputs of max 1024 tokens in length\n",
    "    tgt = val_tgt['text'][i]\n",
    "    tgt = tgt.split()[:tgt_len]\n",
    "    combined = \"<|startoftext|>\" + \" \".join(src) + \" = \" + \" \".join(tgt) + \"<|endoftext|>\"\n",
    "    row['text'] = combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(GPT2/'val-input-text.txt', val_src, fmt='%s', newline=os.linesep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA/'src-test.txt', 'r') as f:\n",
    "    test_src = f.readlines()\n",
    "test_src=pd.DataFrame({'text':test_src})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in test_src.iterrows():\n",
    "    src = row['text'][:-1]\n",
    "    src = src.split()[:512]\n",
    "    src_len = len(src)\n",
    "    combined = \"<|startoftext|>\" + \" \".join(src) + \" = \"\n",
    "    row['text'] = combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(GPT2/'test-input-text.txt', test_src, fmt='%s', newline=os.linesep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
